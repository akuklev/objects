Деконструкция ООП
=================


§ Объекты и Данные
------------------

Когда-то [Tony Hoare](https://en.wikipedia.org/wiki/Tony_Hoare) назвал [null pointers](https://en.wikipedia.org/wiki/Null_pointer) “ошибкой на миллиард долларов”. В истории языков программирования есть кое-что обходящееся, вероятно, ещё дороже: игнорирование фундаментальной разницы между данными и объектами.

С рождения мы воспринимаем окружающий мир и процессы в нём через картины и ощущения, и этого достаточно для мышления при помощи эвристик аналогий. Но чтобы сделать возможными чёткие инструкции и строгие рассуждения, необходимо провести условные границы и разложить мир на **идеализированные единицы моделирования — объекты**. В зависимости от предметной области это могут быть, например, яблоки и груши, ордера и квитанции, поезда и станции или электроны и фотоны. Мы учимся этому, когда учимся говорить и думать словами, а оттачиваем, занимаясь программированием (по части «чётких инструкций») и математикой (по части «строгих рассуждений»). Канонический пример материального объекта в программировании — ячейка памяти, содержащая изменяемое целочисленное значение.

Теперь допустим, что мы считали значение из ячейки памяти и взвесили яблоко, установив, что `X.value = 2` и `Apple1.weight = 93g`. Упоминающиеся тут ячейка памяти `X` и яблоко `Apple1` — материальные объекты, а вот «целое число 2» и «93 грамма» — платонические “объекты”, существующие исключительно в мире математических абстракций. В их отношении мы будем применять термины данные (мн.ч) и значение (ед.ч). **Данные — информация, отделённая от носителя и контекста**.

К объектам применимо понятие “тот же самый, один и тот же” (same). Так в двух разных ящиках могут лежать равные числа, но это не делает их одним и тем же ящиком — если в одном поменять значение, оно не поменяется в другом. Объекты могут возникать/порождаться и исчезать/поглощаться, к ним применимо понятие жизненного цикла (lifecycle).

К значениям, применимо понятие “равный” (equal), но не “тот же”. Быть равными — это свойство пары значений: равенство может быть доказано или опровергнуто, а вот быть одним и тем же объектом можно только по определению. Более того, невозможно вообще корректно определить пару из объекта с самим собой — пара объектов это автоматически пара двух разных объектов.
Также неприменимо к значениям понятие жизненного цикла, про них даже нельзя сказать что они “всегда были и будут” — они просто вне времени и материального мира.

Теперь, ознакомившись с базовыми понятиями и обрисовав фундаментальные различия, давайте разберёмся зачем проектировать языки программирования с учётом этих различий. В примерах я буду пользоваться вымышленным языком с синтаксисом на основе Kotlin'а.

§ Псевдовыражения: Крупнейший источник accidental complexity
------------------------------------------------------------

Первый в современном понимании язык программирования появился в 1957 году, это был FORTRAN. Как и во всех современных императивных языках, программа на Фортране представляет собой последовательность инструкций. Два основных вида инструкций — определения (`a := 1`) и команды (`print("Hello")`). Внутри определений и в качестве аргументов команд могут использоваться выражения:
```kotlin
val a := 60 · 24
print("1 day / 1 min = " ++ a)
```

Выражения описывают как вычислить значение, и взаимозаменимы с этим значением. Выражения представляют из себя деревья применения функций к значениям. Скажем, `60 · 24` предписывает применить функцию `(·)` к значениям 60 и 24, `"1 day / 1 min =  " ++ a` применяет функцию конкатенации строк `(++)` к значениям `"1 day / 1 min = "` и `a` .

Но как это очень часто бывает, концепцией выражений и функций немного злоупотребили. Объединить концепции команды и функции казалось столь соблазнительным, ведь и те и другие могут получать аргументы, а если разрешить командам возвращать значение, можно писать интерактивные программы. Ведь любой запрос, будь он ко внешнему серверу, к пользователю или к ячейке памяти, судь команда, возвращающая значение. Мы будем называть такие команды-функции псевдофункциями, а выражения, содержащие их — псевдовыражениями. В программировании даже сложился особый язык, где слово функция по-умолчанию означает псевдофункцию, в то время как функции, просто детерминистски вычисляющие значение из аргументов, называют чистыми функциями.

Казалось бы, объединение понятий функции и команды это большая экономия концепций, что же тут может быть плохого?
Проблема в том, что нельзя больше рассчитывать, что выражения взаимозаменимы со своими значениями. Теряется удобная ментальная модель, позволяющая думать о программе, просто смотря на неё. Теперь во всяком безобидно выглядящем выражении может скрываться непредсказуемое поведение.

Давайте для примера предположим, что в нашем языке есть псевдофункция под названием `rand()`, недетерминистски генерирующая случайное целое число. Рассмотрим следующие две программы, которые должны бы быть эквивалентны:
```kotlin
val n := rand()
n + n
```
и `rand() + rand()`. Первая программа всегда выдаёт чётное число, ведь она складывает одно и то же случайное число с самим собой, а вторая складывает два независимых случайных числа, и результат вполне может быть нечётным.

Аналогичную проблему вызывает и добавление в язык команды `trace()`, которая никак не влияет на вычисления, а лишь записывает аргумент в лог. Допустим, с целью отладки программисты добавили инструкцию `trace()` в определение функции сложения, и всякий раз при сложении двух чисел выводит их сумму в лог. Такое изменение функции сложения делает выражение использующее операцию сложения не взаимозаменяемым с ее результатом. Если бы функция `(+)` оставалась чистой, следующие три программы обязаны быль эквивалентны:
`(1 + 2) + 3`, `1 + (2 + 3)`, `6`.

С точки зрения результата они действительно эквивалентны, но с точки зрения эффектов неидентичны. Первая при выполнении выведет в лог `3, 6`, вторая `5, 6`, третья не выведет вообще ничего. Полагаясь на подстановочность выражений можно делать мощные оптимизирующие компиляторы, но стоит нам добавить в язык казалось бы безобидную команду `trace()`, оптимизирующие компиляторы входят в непредсказуемый конфликт с пригодностью логов для post-mortem анализа.

Наконец, представте, что мы добавили в язык команду `copy(source, destination)`, которая возвращает количество скопированных файлов. Рассмотрим вот такую программу:
```kotlin
print( copy("*.tmp", dst) · copy("*.*~", dst) )
```

Что хотел сказать этим программист? Можно ли запустить оба процесса копирования одновременно, или нужно сперва произвести копирование слева от оператора `(·)`, а только потом то, которое справа? Если вы уже выбрали предпочтительный ответ, то теперь предположите, что в каталоге вообще не было файлов с расширением `.tmp`, и первая команда возвращает 0. Нужно ли в таком случае вообще производить второе копирование? Если допустимо было запустить оба копирования одновременно, то можно ли напечатать 0 до завершения второго копирования (ведь уже известно, что результат будет 0), или нужно дождаться завершения? Или может быть прервать второй процесс копирования на пол-дороги? Эти решения предстоит принять и описать в спецификации проектировщикам языка, а пользователям языка предстоит их выучить. Вместо очень простой ментальной модели того, как устроены выражения, для понимания псевдовыражений нужно будет знать набор замысловатых правил, которые зачастую “ниоткуда не следуют”, а являются результатом исторической случайности.

И это хорошо ещё, когда команды фигурируют в тексте выражения явно, а не спрятаны внутрь какого-нибудь безобидного выглядящего оператора. Так например в языке Python оператор целочисленного сложения работает совершенно безобидно до тех пор, пока операнды и их сумма составляют менее ~9 квинтиллионов, но превращается в команду встречая переполнение. Такой подход применяется из лучших побуждений — он позволяет свободна работать в Python со сколь угодно длинными целыми числами (пока они влезают в оперативную память), однако в некоторых редких ситуациях невзаимозаменяемость выражения и результата может приводить к некорректному поведению. Причём догадаться о таком подвохе можно лишь обладая экспертными знаниями технических деталей реализации Python.

Псевдовыражения порождают лавину избыточной сложности (accidental complexity). Радикальным решением этой проблемы являются так называемые чисто-функциональные (purely functional) языки программирования, откуда полностью изгнаны команды и оставлены одни выражения.

§ Чисто-функциональные языки
----------------------------

Для большинства из нас концепция объекта куда более привычна, чем концепция значения — потому легко предположить, что значения сложная в понимании и обращении математическая абстракция, в то время как объекты просты и наглядны. На деле ситуация обстоит противоположным образом:  
Для описания свойств и взаимоотношений значений, и строгих рассуждений о них математики ещё полтора века назад [Frege1879] разработали формализованный язык, называемый **исчислением предикатов**. Десятилетия теоретических исследований и практического использования исчисления предикатов позволили убедиться в его корректности и достаточной выразительности, понять все его возможности и ограничения, выработать удобный синтаксис. 

Когда говорят о чисто-функциональных языках программирования, часто упоминают, что у них есть “математическая основа“. Что имеется в виду и какие преимущества это даёт?

Чисто-функциональные языки программирования оперируют напрямую только и исключительно данными, а для рассуждений о данных имеется развитый математический инструментарий. Из этого вытекает два перимущества теоретического и практического порядка соответственно:
1. Выразительность исчисления предикатов гарантирует, что все свойства программ на чисто-функциональных языках программирования, не завиящие от устройства компилятора и модели вычисления, можно сформулировать. Можно сформулировать требование, что функция `sort` всегда правильно сортирует, а функция `groupBy` правильно группирует. Имеются техники для анализа, в полной ли мере те или иные требования характеризуют функцию. Они позволяют найти неучтённые пограничные случаи, либо убедиться в их отсутствии.
2. На практике условия корректности очень редко выписывают в явном виде, но само понимание как это делать, позволяет выработать достоверную ментальную модель — неформальный способ думать о программах, что позволяет писать корректные-по-построению программы, и именно в этом состоит главное практическое преимущество “математической фундированности” строго-функциональных языков. Ведь условия корректности редко выписывают вовсе не из-за лени, а потому, что их всё равно никто не будет читать. А вот хорошо структурированный, литературно написанный и очевидно корректный-по-построению код — лучшая спецификация и лучшая документация самому себе*. 

(* Человеческий мозг плохо приспособлен к обобщениям без примеров и склонен упускать мелочи, поэтому 
хорошая документация/спецификация должна включать ещё и тесты-примеры, включающие пару типовых сценариев использования и все corner cases.)

Несмотря на все эти преимущества, чисто-функциональные языки имеют и ограничения. Некоторые прикладные задачи, например создание интерактивных приложений и распределённых систем, не сводятся напрямую к преобразованию данных. Чтобы заниматься этими задачами на чисто-функциональных языках, приходится прибегать к использованию замысловатой машинерии, позволяющей окольными путями описывать манипуляции объектами на языках, лишенных возможности упоминать объекты напрямую.

Для решения именно таких задач спроектированы современные мультипарадигменные языки, такие как Kotlin, Rust и Scala, позволяющие оперировать напрямую не только данными, но и объектами. Но как распространить на них вышеописанные преимущества функциональных языков?

Первым условием для этого является тщательное размежевание объектов и данных. Ниже я продемонстрирую, как шаг за шагом добавить в чисто-функциональный язык программирования императивные элементы, не теряя возможости строго описывать свойства программ. Начав с надёжного “чисто-функционального” фундаменты мы реконструием мультепарадигменный язык и “переизобретём” как можно думать об объектах, эффектах и взаимодействующих процессах понятным и непротиворечивым образом. В примерах я буду использовать вымышленный чисто-функциональный язык с синтаксисом на основе Kotlin'а.

Даже если вы не намереваетесь заниматься формальной верификацией и вообще когда-либо пользоваться таким языком программирования, понимание его устройства поможет лучше понять многие моменты, касающиеся параллелизации, out-of-order execution, а также многие тонкости, постоянно возникающие в многопоточном программировании.

* * *

§ Чисто-функциональные языки
----------------------------

Программы на императивных языках программирования в первом приближении представляют из себя последовательность инструкций — приказов компьютеру (или переферийному устройству) совершить какое-либо действие. Скажем `print("Hello")` это инструкция напечатать слово “Hello”.

В чисто-функциональных языках программирования не существует такой синтаксической категории как инструкции. В таких языках есть лишь выражения (`2·a + 3`) и определения (`a := 1`, `f(x) := x`).  
Выражения описывают как вычислить значение, и взаимозаменимы с этим значением. Определения служат лишь для удобства, все определения можно убрать, заменив каждое упоминание определяемого на соответствующее определение, и программа останется идентичной.

При наличии инструкций заменяемость на значение уже не работает. 

§ Инструкции и программы
------------------------

Рассмотрим выражение `2·a + 3`. В нём используются два литерала (2 и 3) и три так называемых символа: численная переменная `a` и два бинарных оператора на числах — `(+)` и `(·)`. Контекстом называется набор доступных для использования внутри выражения символов и операторов с указанием их сигнатур, в частности для выражения `2·a + 3` контекст выглядит следующим образом:
```
a : Int, (+) : Int -> Int -> Int, (·) : Int -> Int -> Int
```

В чисто-функциональных языках программирвоания все символы и операторы представляют собой значения и являются либо константами, определёнными выше по течению или импортированными в скоуп, либо именами аргументов функций, внутри которых мы находимся. Более того, константы всегда могут быть выражены через создание и немедленное применение анонимной функции:
```kotlin
val a := expr
2·a + 3
```
— это то же самое, что `expr ▸ {a ↦ 2·a + 3}`, где `(▸)` оператор применения справа налево `x ▸ f` := `f(x)`.

Программой (routine) мы будем называть последовательность инструкций, возможно с ветвлениями и циклами. Инструкции (statements) внешне похожи на выражения, но их контексты могут содержать особые операторы, представляющие собой не значения, а действия или запросы, такие как вышеприведённые `!rand` и `!trace`. Как было объяснено выше, такие операторы не взаимозаменяемы с результатом своего вызова. Чтобы это радикально отличающее их свойство сразу было заметно, мы будем всегда начинать из названия с восклицательного знака. Отметим также, что хорошо знакомые всем программистам инструкции `throw` и `return` тоже можно рассматривать как !-операторы.

В зависимости от своей сигнатуры !-операторы бывают:
* одноразовыми (one-shot), как `!throw` — в каждой ветви выполнения такой оператор можно использовать не более одного раза
* принудительно одноразовыми (obligatory one-shot), как `!return` — в каждой ветви выполнения такой оператор можно и необходимо использовать ровно один раз
* параллельно многоразовыми, как `!rand` — такой оператор можно использовать произвольное число раз, причём даже более одного раза внутри одной инструкции; в отношении таких операторов важен только сам факт каждого вызова, но играет роли в каком порядке совершаются эти вызовы.
* последовательно многоразовыми как `!trace` — в программе такой оператор можно использовать много раз, но в каждой отдельной инструкции не более одного раза. Для последовательно многоразовых операторов существенен порядок вызовов. Более того, сама сигнатура оператора может меняться после каждого вызова (мы выбрали Котлин в частности потому, что он поддерживает smart-касты). “Под капотом” последовательно многоразовые !-операторы это одноразовые операторы, которые после вызова возвращают в контекст новый !-оператор с таким же названием вместо себя.

Обозначения для типов !-операторов проистекают из так называемой линейной логики.
Тип принудительно одноразового !-оператора будем обозначать через `X ⊸ Y`:
```kotlin
!return : T ⊸ Nothing
```

Тип (не более чем) одноразового !-оператора будем обозначать через `¿T`:
```kotlin
!throw : ¿(Throwable ⊸ Nothing)
```

Тип параллельно-многразового !-оператора будем обозначать через `!T`:
```
!rand : !Int
```

Как же описать тип `T` последовательно-многоразового оператора `!trace`? Напомню, что “под капотом” многоразовые !-операторы суть одноразовые, возвращающие (возможно наряду с некоторым значением) свою замену. Стало быть тип `T` оператора `!trace` должен удовлетворять рекурсивному соотношению `T = String ⊸ T`. Для порождения типов !-операторов, удовлетворяющих подобным рекурсивным соотношениям мы будем использовать специальные сигнатуры уже хорошо знакомые пользователям Котлина. Они называются там интерфейсами:
```
interface Log {
  fun !trace(msg : String)
}
```

§ Объекты и Интерфейсы
----------------------

Выше уже упоминался хрестоматийный пример объекта — изменяемая (мутабельная) переменная. На Котлине её интерфейс можно было бы описать так:
```kotlin
interface Variable<T> {
   val !get : T
   fun !set(v : T)
}
```

В нашем расширении чисто-функционального Котлин мы допустим определения интерфейсов, но не будем разрешать использовать интерфейсы в качестве типов аргументов, переменных и возвращаемых значений. Таким образом мы эффективно потребуем, чтобы типы всех методов и свойств, декларируемых в интерфейсах, равно как и типы их аргументов были типами значений.

Как же можно использовать интерфейсы, если мы пока запрещаем чтобы переменные или аргументы функций использовали интерфейсы в качестве типов? А очень просто — используя механизм, известный в Котлине как extension methods. Для всякого интерфейса I мы можем написать новый метод `foo`
```kotlin
fun I.foo(args) : ResultT {
   ...
}
```
в теле которого все методы, описанные в интерфейсе I, доступны в качестве !-операторов. Объекты — сущности удовлетворяющие интерфейсам, мы не видим их напрямую в языке, но имеем к ним доступ через их методы. Имеющееся в распоряжении в Котлине механизмы описания интерфейсов позволяют описывать всевозможные мутабельные объекты и внешние сервисы с заданным интерфейсом. В этом случае методы — запросы к такому сервису.

Небольшое расширение синтаксиса интерфейсов позволит добавить поддержку нетривиального жизненного цикла объектов. Мы позволим методам в интерфейсах менять тип this (мы выбрали Котлин в частности потому, что он поддерживает smart-касты). В частности, можно поменять тип this на Nothing и таким образом указать, что метод поглащает объект, на котором был вызван:
```kotlin
interface OutputStream {
   fun !append(s : String)
   fun !close() nextState(Nothing)
}
```

Теперь вместо постоянного набора методов имеется конечный автомат состояний объекта, и доступные методы зависят от текущего состояния. Диаграма этого конечного автомата описывает жизненный цикл объекта.


Если сделать Котлин зависимо-типизированным языком (то есть таким, что параметрами типов могут являться значения, например `List<T, size = n>`), то в интерфейсах допустимо, чтобы типы возвращаемых значений методов и состояния, в которые переходит в результате вызова метода this, зависели от аргументов метода и параметров исходного типа this. (NB: Для знатоков теории категорий отмечу что этими расширениями интерфейсы соответствуют свободно-порождённым зависимым комонадам. Зависимые комонады также известны как правые расширения Кана.)

Используя синтаксис val (properties with a getter) в интерфейсах, мы можем также описать `!rand`: 
```kotlin
interface RandGen {
  val !rand: Int
}
```

Использование в extension methods не единственный способ использования объектов. Ниже мы опишем, например, ситуации, когда мы можем локально породить изолированный объект, поработать с ним, а затем закрыть его, извлекая значение — так работают Котлиновские typesafe-builder'ы. Изолированные объекты можно будет также одалживать, принимать и передавать во владение, но прежде нам необходимо дать определение изолированным объектам.

Равенство объектов
------------------

В мире объектов понятие равенства распадается на две модальности — равенство эффектов и равенство
результатов, которые мы будем обозначать через =e= и =r= соответственно.

Используя равенство эффектов мы можем указать важнейшее свойство оператора `!rand` — отсутствие побочных эффектов:
```kotlin
interface RandGen {
  val !rand: Int
  
  contracts {
    {!rand} =e= {}
  }
}
```

Равенство результатов вообще говоря нерефлексивное, например `!rand =r= !rand` НЕ
выполняется. Оператор `!foo : X ⊸ Y` называется детерминированным в точности, если
для него выполняется рефлексивность равенства результатов, т. е.
будучи вызван с одинаковым аргументом он всякий раз выдаёт одинаковые результат:
`a = b` влечёт `!foo(a) =r= !foo(b)`.

Также обратим внимание, что равенство результатов не влечёт равенства эффектов:
с точки зрения результатов любые два запроса, возвращающие Unit, равны, но с точки зрения
эффектов `!trace("Hello")` и `!trace("Goodbye")` очевидно разные.

Равенство эффектов напротив рефлексивное, но не влечёт равенства результатов. Равенство эффектов
может быть использована для выражения независимости (параллелизуемости) запросов. Мы можем, например,
постулировать, что запись в независимые потоки вывода (например, `!print` и `!trace`) коммутирует:
```kotlin
{!print(x); !trace(y)} =e= {!trace(y); !print(x)}
```

Информация о коммутировании тех или иных вызовов открывает богатые возможности для оптимизирующей
компиляции: компилятор, если это способно повысить производительность, может переставлять вызовы местами или даже вовсе параллелизовать их.

Объекты obj1 и obj2 называют независимыми вызовы методов obj1 и методов obj2 коммутируют между собой.
Независимость объектов имплицирует отсутствие коммуникации между ними, но не означает
детерминированности.

Изолированным называется объект независимых от любых других объектов. Для `RandGen` и `Log`лога это
свойство постулируется*, для детерминистски работающих мутабельных объектов выполняется по построению. 

(* Мы постулируем, что считывание из собственных логов невозможно в рантайме ни прямо, ни опосредованно, иначе логи можно было бы использовать как хранилище информации.)

Методами теории категорий можно показать, что с процедурой, использующей изолированные  
детерминированные объекты, и не экспортирующей их наружу, можно обращаться в точности
также как если бы она была чистой функцией. Благодаря этому обстоятельству в случае изолированных объектов можно допустить передачу и получение объектов в качестве аргументов функции при контроли владения (см. Rust).

В заключение секции приведём описание интерфейса `мутабельная переменная` с контрактами, в полной мере определяющими её поведение:

```kotlin
interface Variable<T> {
   val !get : T?
   fun !set(v : T)
   
   contracts {
     !get =r= !get
     {!get} =e= {}

     {!set(x1); !set(x2)} =e= {!set(x2)}     
     {!set(x); !get} =r= x     
   }
}
```

Обратите внимание, что из контрактов и сигнатуры прямо следует, что `!get` может возвращать `null` только до первого вызова `!set`, но не очевидно, что он обязан выдавать именно `null` до первого вызова `!set`. Однако легко показать, что это единственное возможное поведение, если в качестве параметра `T` подставить `Nothing`, а из параметричности следует что при использовании любого другого типа поведение должно оставаться таким же.

Открытый вопрос 1: Такого рода описания должны порождать монаду Дейкстры (https://arxiv.org/abs/1903.01237), предоставляющую удобный инструмент для формальной верификации программ. Как именно построить монаду дейкстры для произвольного интерфейса, снабженного исчерпывающими контрактами?

Открытый вопрос 2: Как именно контракты и монады Дейкстры связаны с сепарационной логикой?

Открытый вопрос 3: Как взаимодействуют и взаимосвязаны объекты и корутины? Свет эти вопросы с теоретической точки зрения проливает линейная логика Girard'а и её расширения, в первую очередь Adjoint logics Frank'а Pfenning'а. С практической точки зрения механизмы взаимодействия должны быть описуемы в терминах join calculus.